{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luck1e23/STA160-Team-11-Project/blob/laiq/Resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiZ1rXakVHbF",
        "outputId": "496f9ac5-ba9b-4383-9a92-b455c09eb434"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vuh0Wl8AVX0V",
        "outputId": "57a78154-8908-4937-cda4-f5cae893c060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchxrayvision\n",
            "  Downloading torchxrayvision-1.4.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: torch>=1 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (0.24.0+cu126)\n",
            "Requirement already satisfied: scikit-image>=0.16 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (0.25.2)\n",
            "Requirement already satisfied: tqdm>=4 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.2.2)\n",
            "Requirement already satisfied: requests>=1 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.32.4)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (11.3.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.37.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1->torchxrayvision) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1->torchxrayvision) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1->torchxrayvision) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=1->torchxrayvision) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=1->torchxrayvision) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=1->torchxrayvision) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=1->torchxrayvision) (2025.11.12)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (1.16.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (3.6)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1->torchxrayvision) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1->torchxrayvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1->torchxrayvision) (3.0.3)\n",
            "Downloading torchxrayvision-1.4.0-py3-none-any.whl (29.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchxrayvision\n",
            "Successfully installed torchxrayvision-1.4.0\n",
            "Collecting iterative-stratification\n",
            "  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from iterative-stratification) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from iterative-stratification) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from iterative-stratification) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->iterative-stratification) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\n",
            "Downloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\n",
            "Installing collected packages: iterative-stratification\n",
            "Successfully installed iterative-stratification-0.1.9\n",
            "Collecting validators\n",
            "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: validators\n",
            "Successfully installed validators-0.35.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchxrayvision\n",
        "!pip install iterative-stratification\n",
        "!pip install validators matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3_tYWUt_VZnt"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim import Adam\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
        "from pathlib import Path\n",
        "\n",
        "# Visualization tools\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as transforms\n",
        "import torchvision.transforms.functional as tvF\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Pre-trained Model: torchxrayvision\n",
        "import torchxrayvision as xrv\n",
        "import skimage\n",
        "from torchvision.models import resnet50, ResNet50_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KoFXKT7tWEqv"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7ODFdXfmWJqm"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/Shareddrives/STA_160/dataset/Data_Entry_2017.csv'\n",
        "train_val = '/content/drive/Shareddrives/STA_160/dataset/train_val_list.txt'\n",
        "test = '/content/drive/Shareddrives/STA_160/dataset/test_list.txt'\n",
        "resized_root = '/content/dataset_resized'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eZNXSD2bWM8-"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/Shareddrives/STA_160/NIH_resized.zip -d /content/dataset\n",
        "\n",
        "!mkdir -p /content/dataset_resized\n",
        "# Finds all image files inside subfolders\n",
        "!find /content/dataset/content/dataset_resized/ -type f -exec mv -t /content/dataset_resized/ {} +\n",
        "!rm -rf /content/dataset/content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PEvt8OdkapCP"
      },
      "outputs": [],
      "source": [
        "### Dataset\n",
        "\n",
        "class NIHXrays(Dataset):\n",
        "    def __init__(self, file_path, dataset_root, list_file=None, transform=None):\n",
        "        self.data = pd.read_csv(file_path)\n",
        "        self.dataset_root = dataset_root\n",
        "        self.transform = transform\n",
        "\n",
        "        # Optional filtering by train_val_list or test_list\n",
        "        if list_file:\n",
        "            with open(list_file, 'r') as f:\n",
        "                image_list = {line.strip() for line in f.readlines()}\n",
        "            self.data = self.data[self.data['Image Index'].isin(image_list)].reset_index(drop=True)\n",
        "\n",
        "        # Create label map\n",
        "        all_labels = set()\n",
        "        for labels in self.data['Finding Labels']:\n",
        "            for l in labels.split('|'):\n",
        "                all_labels.add(l.strip())\n",
        "\n",
        "        self.all_labels = sorted(all_labels)\n",
        "        self.label_map = {label: i for i, label in enumerate(self.all_labels)}\n",
        "\n",
        "        # Build multi hot label vectors\n",
        "        self.finding_labels = []\n",
        "        for labels in self.data['Finding Labels']:\n",
        "            vec = torch.zeros(len(self.all_labels))\n",
        "            for l in labels.split('|'):\n",
        "                if l.strip() in self.label_map:\n",
        "                    vec[self.label_map[l.strip()]] = 1.0\n",
        "            self.finding_labels.append(vec)\n",
        "\n",
        "        self.finding_labels = torch.stack(self.finding_labels).float()\n",
        "\n",
        "        # Recursively map image filenames to full paths\n",
        "        self.image_map = {}\n",
        "        for img_path in Path(dataset_root).rglob(\"*.png\"):\n",
        "            self.image_map[img_path.name] = str(img_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.data.iloc[idx]['Image Index']\n",
        "\n",
        "        if img_name not in self.image_map:\n",
        "            raise FileNotFoundError(f\"Image {img_name} not found.\")\n",
        "\n",
        "        # Load image as grayscale first\n",
        "        img = Image.open(self.image_map[img_name]).convert(\"L\")\n",
        "\n",
        "        # Apply augmentation on the PIL image\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # Convert to NumPy and scale to [0, 1]\n",
        "        img = np.array(img).astype(np.float32) / 255.0  # [H, W]\n",
        "\n",
        "        # To tensor with shape [1, H, W]\n",
        "        img = torch.from_numpy(img).unsqueeze(0)\n",
        "\n",
        "        # Repeat to make 3 channels for ResNet50: [3, H, W]\n",
        "        img = img.repeat(3, 1, 1)\n",
        "\n",
        "        # ImageNet normalization for ResNet50\n",
        "        img = tvF.normalize(\n",
        "            img,\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "\n",
        "        label = self.finding_labels[idx].float()\n",
        "\n",
        "        return img, label, img_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0jzzP6uar3_",
        "outputId": "ced33b12-82c1-4128-917f-3f0bb0d7f517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train+val images: 86524\n",
            "Number of test images: 25596\n",
            "Label set: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n"
          ]
        }
      ],
      "source": [
        "# Data augmentation for training\n",
        "rand_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip()\n",
        "])\n",
        "\n",
        "train_val_data = NIHXrays(file_path, resized_root, list_file=train_val, transform=rand_transforms)\n",
        "test_data      = NIHXrays(file_path, resized_root, list_file=test, transform=None)\n",
        "\n",
        "print(\"Number of train+val images:\", len(train_val_data))\n",
        "print(\"Number of test images:\", len(test_data))\n",
        "print(\"Label set:\", train_val_data.all_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHh__8mbawL7",
        "outputId": "6d59a168-100d-4199-d49e-e8df8746dde6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 69200\n",
            "Valid samples: 17324\n"
          ]
        }
      ],
      "source": [
        "### Multi label stratified split\n",
        "\n",
        "y = train_val_data.finding_labels.numpy()   # [N, C]\n",
        "X = np.arange(len(train_val_data))\n",
        "\n",
        "msss = MultilabelStratifiedShuffleSplit(\n",
        "    n_splits=1,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_idx, valid_idx = next(msss.split(X, y))\n",
        "\n",
        "train_data = Subset(train_val_data, train_idx)\n",
        "valid_data = Subset(train_val_data, valid_idx)\n",
        "\n",
        "print(\"Train samples:\", len(train_data))\n",
        "print(\"Valid samples:\", len(valid_data))\n",
        "\n",
        "### DataLoaders\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True,\n",
        "                          num_workers=2, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=False,\n",
        "                          num_workers=2, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB6y_-fcbFib",
        "outputId": "3adadbe8-bac9-4602-80e9-d623922b17d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 15\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 173MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torchvision ResNet50 backbone\n",
            "Trainable params in fc: 30735\n"
          ]
        }
      ],
      "source": [
        "### ResNet50 model\n",
        "\n",
        "# Number of output classes from dataset\n",
        "N_CLASSES = len(train_val_data.all_labels)\n",
        "print(\"Number of classes:\", N_CLASSES)\n",
        "\n",
        "# Pretrained ResNet50 from torchvision (ImageNet weights)\n",
        "weights = ResNet50_Weights.IMAGENET1K_V2\n",
        "resnet_model = resnet50(weights=weights)\n",
        "\n",
        "# Replace final fully connected layer\n",
        "in_features = resnet_model.fc.in_features\n",
        "resnet_model.fc = nn.Linear(in_features, N_CLASSES)\n",
        "\n",
        "# First stage: freeze all layers except the new head\n",
        "for param in resnet_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in resnet_model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "resnet_model = resnet_model.to(device)\n",
        "\n",
        "print(\"Using torchvision ResNet50 backbone\")\n",
        "print(\"Trainable params in fc:\", sum(p.numel() for p in resnet_model.fc.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QiMjxE-nbOER"
      },
      "outputs": [],
      "source": [
        "### Loss function and optimizer\n",
        "\n",
        "def compute_pos_weights(subset):\n",
        "    full_dataset = subset.dataset\n",
        "    labels = full_dataset.finding_labels[subset.indices].numpy()\n",
        "\n",
        "    pos_counts = labels.sum(axis=0)\n",
        "    neg_counts = (labels == 0).sum(axis=0)\n",
        "    pos_weight = neg_counts / (pos_counts + 1e-6)\n",
        "\n",
        "    return torch.tensor(pos_weight, dtype=torch.float32)\n",
        "\n",
        "pos_weight = compute_pos_weights(train_data).to(device)\n",
        "pos_weight = torch.clamp(pos_weight, max=30)\n",
        "\n",
        "class Focal_Loss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, pos_weight=None):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.pos_weight = pos_weight\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        bce = F.binary_cross_entropy_with_logits(\n",
        "            logits,\n",
        "            targets,\n",
        "            pos_weight=self.pos_weight,\n",
        "            reduction='none'\n",
        "        )\n",
        "\n",
        "        probs = torch.sigmoid(logits)\n",
        "        p_t = probs * targets + (1 - probs) * (1 - targets)\n",
        "\n",
        "        focal_factor = (1 - p_t) ** self.gamma\n",
        "        loss = focal_factor * bce\n",
        "        return loss.mean()\n",
        "\n",
        "loss_function = Focal_Loss(gamma=2.0, pos_weight=pos_weight)\n",
        "\n",
        "optimizer = Adam(resnet_model.fc.parameters(), lr=1e-3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pOAuxOhLbQ2p"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve\n",
        "\n",
        "def pr_curve_thresholds(y_true, y_prob, min_thresh=0.1):\n",
        "    num_labels = y_true.shape[1]\n",
        "    thresholds = np.zeros(num_labels)\n",
        "\n",
        "    for i in range(num_labels):\n",
        "        p, r, t = precision_recall_curve(y_true[:, i], y_prob[:, i])\n",
        "        f1 = 2 * p * r / (p + r + 1e-9)\n",
        "\n",
        "        if len(t) == 0:\n",
        "            thresholds[i] = min_thresh\n",
        "        else:\n",
        "            thresholds[i] = t[np.argmax(f1)]\n",
        "\n",
        "    return thresholds\n",
        "\n",
        "def compute_f1(y_true, y_prob, thresholds):\n",
        "    y_true = y_true.cpu()\n",
        "    y_prob = y_prob.cpu()\n",
        "\n",
        "    thresholds = torch.tensor(thresholds, dtype=y_prob.dtype)\n",
        "    y_pred = (y_prob >= thresholds.unsqueeze(0)).int()\n",
        "\n",
        "    return f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "def compute_auc(y_true, y_prob):\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_prob = y_prob.detach().cpu().numpy()\n",
        "    return roc_auc_score(y_true, y_prob, average=\"macro\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KIbWnEivbS0Z"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader, optimizer, loss_fn, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    for imgs, labels, _ in train_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        batch_loss = loss_fn(outputs, labels)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += batch_loss.item()\n",
        "\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        all_probs.append(probs.detach().cpu())\n",
        "        all_labels.append(labels.detach().cpu())\n",
        "\n",
        "    all_probs = torch.cat(all_probs)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    auc = compute_auc(all_labels, all_probs)\n",
        "    epoch_loss = total_loss / len(train_loader)\n",
        "\n",
        "    print(f\"Train - Loss: {epoch_loss:.4f}, AUC: {auc:.4f}\")\n",
        "    return epoch_loss, auc\n",
        "\n",
        "\n",
        "def validate_epoch(model, valid_loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels, _ in valid_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            batch_loss = loss_fn(outputs, labels)\n",
        "\n",
        "            total_loss += batch_loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            all_probs.append(probs.detach().cpu())\n",
        "            all_labels.append(labels.detach().cpu())\n",
        "\n",
        "    all_probs = torch.cat(all_probs)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    epoch_loss = total_loss / len(valid_loader)\n",
        "    thresholds = pr_curve_thresholds(all_labels.numpy(), all_probs.numpy())\n",
        "    valid_f1 = compute_f1(all_labels, all_probs, thresholds)\n",
        "    valid_auc = compute_auc(all_labels, all_probs)\n",
        "\n",
        "    print(f\"Valid - Loss: {epoch_loss:.4f}, F1: {valid_f1:.4f}, AUC: {valid_auc:.4f}\")\n",
        "    return epoch_loss, valid_f1, valid_auc, thresholds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fqomQHBbXde",
        "outputId": "8a3b49f4-aff5-48d6-9a95-a72b22fb0e3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "Train - Loss: 0.2478, AUC: 0.6624\n",
            "Valid - Loss: 0.2440, F1: 0.1987, AUC: 0.7078\n",
            "New best ResNet50 model saved with AUC 0.7078\n",
            "\n",
            "Epoch 2/5\n",
            "Train - Loss: 0.2424, AUC: 0.6962\n",
            "Valid - Loss: 0.2434, F1: 0.2030, AUC: 0.7150\n",
            "New best ResNet50 model saved with AUC 0.7150\n",
            "\n",
            "Epoch 3/5\n",
            "Train - Loss: 0.2411, AUC: 0.7066\n",
            "Valid - Loss: 0.2406, F1: 0.2064, AUC: 0.7185\n",
            "New best ResNet50 model saved with AUC 0.7185\n",
            "\n",
            "Epoch 4/5\n",
            "Train - Loss: 0.2404, AUC: 0.7108\n",
            "Valid - Loss: 0.2441, F1: 0.2017, AUC: 0.7132\n",
            "\n",
            "Epoch 5/5\n",
            "Train - Loss: 0.2404, AUC: 0.7133\n",
            "Valid - Loss: 0.2424, F1: 0.2117, AUC: 0.7181\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5\n",
        "best_val_auc = 0.0\n",
        "best_model_path_resnet = \"/content/drive/Shareddrives/STA_160/nih_resnet50_finetuned_best_head.pth\"\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
        "\n",
        "    train_loss, train_auc = train_epoch(\n",
        "        model=resnet_model,\n",
        "        train_loader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        loss_fn=loss_function,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    valid_loss, valid_f1, valid_auc, thresholds = validate_epoch(\n",
        "        model=resnet_model,\n",
        "        valid_loader=valid_loader,\n",
        "        loss_fn=loss_function,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    if valid_auc > best_val_auc:\n",
        "        best_val_auc = valid_auc\n",
        "        torch.save(resnet_model.state_dict(), best_model_path_resnet)\n",
        "        print(f\"New best ResNet50 model saved with AUC {best_val_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in resnet_model.named_parameters():\n",
        "    if name.startswith(\"layer4\") or name.startswith(\"fc\"):\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# New optimizer with smaller LR for backbone, slightly higher for head\n",
        "optimizer = Adam([\n",
        "    {\n",
        "        \"params\": [p for n, p in resnet_model.named_parameters()\n",
        "                   if n.startswith(\"layer4\") and p.requires_grad],\n",
        "        \"lr\": 1e-5\n",
        "    },\n",
        "    {\n",
        "        \"params\": resnet_model.fc.parameters(),\n",
        "        \"lr\": 1e-4\n",
        "    }\n",
        "])"
      ],
      "metadata": {
        "id": "azPYgYkIlSQv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS_FINE = 10\n",
        "best_val_auc_fine = 0.0\n",
        "best_model_path_resnet_fine = \"/content/drive/Shareddrives/STA_160/nih_resnet50_finetuned_best_full.pth\"\n",
        "\n",
        "for epoch in range(EPOCHS_FINE):\n",
        "    print(f\"\\nFine tune Epoch {epoch + 1}/{EPOCHS_FINE}\")\n",
        "\n",
        "    train_loss, train_auc = train_epoch(\n",
        "        model=resnet_model,\n",
        "        train_loader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        loss_fn=loss_function,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    valid_loss, valid_f1, valid_auc, thresholds = validate_epoch(\n",
        "        model=resnet_model,\n",
        "        valid_loader=valid_loader,\n",
        "        loss_fn=loss_function,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    if valid_auc > best_val_auc_fine:\n",
        "        best_val_auc_fine = valid_auc\n",
        "        torch.save(resnet_model.state_dict(), best_model_path_resnet_fine)\n",
        "        print(f\"New best fine tuned ResNet50 saved with AUC {best_val_auc_fine:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DNjEbbRmZvt",
        "outputId": "d25d1b1d-1838-4449-9e4a-4cf68a5d5a80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fine tune Epoch 1/10\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMDlnBF/Y70xLrG6kIoD8x0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}