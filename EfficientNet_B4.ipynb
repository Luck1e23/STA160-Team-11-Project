{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMAg0AjTReKSQGjezrel9B7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luck1e23/STA160-Team-11-Project/blob/Tina/EfficientNet_B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cj7iDbtGuy0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de06aa7d-eab9-4aa1-a989-51888262ff12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchxrayvision\n",
        "!pip install iterative-stratification\n",
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrFdddGgwGnr",
        "outputId": "6085978a-85fa-4926-d42f-fd52308c54fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchxrayvision\n",
            "  Downloading torchxrayvision-1.4.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: torch>=1 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (0.24.0+cu126)\n",
            "Requirement already satisfied: scikit-image>=0.16 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (0.25.2)\n",
            "Requirement already satisfied: tqdm>=4 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.2.2)\n",
            "Requirement already satisfied: requests>=1 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.32.4)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (11.3.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.37.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1->torchxrayvision) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1->torchxrayvision) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1->torchxrayvision) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=1->torchxrayvision) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=1->torchxrayvision) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=1->torchxrayvision) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=1->torchxrayvision) (2025.11.12)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (1.16.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (3.6)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1->torchxrayvision) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1->torchxrayvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1->torchxrayvision) (3.0.3)\n",
            "Downloading torchxrayvision-1.4.0-py3-none-any.whl (29.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchxrayvision\n",
            "Successfully installed torchxrayvision-1.4.0\n",
            "Collecting iterative-stratification\n",
            "  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from iterative-stratification) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from iterative-stratification) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from iterative-stratification) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->iterative-stratification) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\n",
            "Downloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\n",
            "Installing collected packages: iterative-stratification\n",
            "Successfully installed iterative-stratification-0.1.9\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from efficientnet_pytorch) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->efficientnet_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->efficientnet_pytorch) (3.0.3)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=367c25889867888e750a5b48b7d8b52c0195b3a7706be8ee535e469af9b8eb6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/3f/43/e6271c7026fe08c185da2be23c98c8e87477d3db63f41f32ad\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim import Adam\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
        "from pathlib import Path\n",
        "\n",
        "# Visualization tools\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Pre-trained Model: torchxrayvision\n",
        "import torchxrayvision as xrv\n",
        "import skimage\n",
        "\n",
        "# Pre-trained Modedl: EfficientNet\n",
        "from efficientnet_pytorch import EfficientNet\n"
      ],
      "metadata": {
        "id": "iZDo4vtWwISa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "file_path = '/content/drive/Shareddrives/STA_160/dataset/Data_Entry_2017.csv'\n",
        "train_val = '/content/drive/Shareddrives/STA_160/dataset/train_val_list.txt'\n",
        "test = '/content/drive/Shareddrives/STA_160/dataset/test_list.txt'\n",
        "resized_root = '/content/dataset_resized'   # Where resized images will be saved"
      ],
      "metadata": {
        "id": "5fbg1Xr7wKgY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "7vhGbPTzyunq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzipping the resized dataset from shared drives\n",
        "!unzip -q /content/drive/Shareddrives/STA_160/NIH_resized.zip -d /content/dataset\n",
        "\n",
        "!mkdir -p /content/dataset_resized\n",
        "# Finds all image files inside subfolders\n",
        "!find /content/dataset/content/dataset_resized/ -type f -exec mv -t /content/dataset_resized/ {} +\n",
        "!rm -rf /content/dataset/content #remove folder"
      ],
      "metadata": {
        "id": "fTBde1BgwO9a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Class\n",
        "class NIHXrays(Dataset):\n",
        "    def __init__(self, file_path, dataset_root, list_file=None, transform=None):\n",
        "        self.data = pd.read_csv(file_path)\n",
        "        self.dataset_root = dataset_root\n",
        "        self.transform = transform\n",
        "\n",
        "        # Optional filtering\n",
        "        if list_file:\n",
        "            with open(list_file, 'r') as f:\n",
        "                image_list = {line.strip() for line in f.readlines()}\n",
        "            self.data = self.data[self.data['Image Index'].isin(image_list)].reset_index(drop=True)\n",
        "\n",
        "        # Create label map\n",
        "        all_labels = set()\n",
        "        for labels in self.data['Finding Labels']:\n",
        "            for l in labels.split('|'):\n",
        "                all_labels.add(l.strip())\n",
        "\n",
        "        self.all_labels = sorted(all_labels)\n",
        "        self.label_map = {label: i for i, label in enumerate(self.all_labels)}\n",
        "\n",
        "        # Build multi-hot label vectors\n",
        "        self.finding_labels = []\n",
        "        for labels in self.data['Finding Labels']:\n",
        "            vec = torch.zeros(len(self.all_labels))\n",
        "            for l in labels.split('|'):\n",
        "                if l.strip() in self.label_map:\n",
        "                    vec[self.label_map[l.strip()]] = 1.0\n",
        "            self.finding_labels.append(vec)\n",
        "\n",
        "        self.finding_labels = torch.stack(self.finding_labels).float()\n",
        "\n",
        "        # Recursively map image filenames to full paths\n",
        "        self.image_map = {}\n",
        "        for img_path in Path(dataset_root).rglob(\"*.png\"):\n",
        "            self.image_map[img_path.name] = str(img_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.data.iloc[idx]['Image Index']\n",
        "\n",
        "        if img_name not in self.image_map:\n",
        "            raise FileNotFoundError(f\"Image {img_name} not found.\")\n",
        "\n",
        "        # Load Image\n",
        "        img = Image.open(self.image_map[img_name]).convert(\"L\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "          img = self.transform(img)\n",
        "\n",
        "        img = np.array(img).astype(np.float32) # PIL image --> NumPy\n",
        "\n",
        "        # XRV normalizaiton\n",
        "        img = xrv.datasets.normalize(img, maxval=255)\n",
        "\n",
        "        #   NumPy --> Tensor\n",
        "        img = torch.from_numpy(img).unsqueeze(0)\n",
        "\n",
        "        label = self.finding_labels[idx].float()\n",
        "\n",
        "        return img, label, img_name"
      ],
      "metadata": {
        "id": "P_b9OXF-wQvk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "rand_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip()\n",
        "])\n",
        "\n",
        "train_val_data = NIHXrays(file_path, resized_root, list_file=train_val, transform=rand_transforms)\n",
        "test_data      = NIHXrays(file_path, resized_root, list_file=test, transform=None)"
      ],
      "metadata": {
        "id": "IBpAZ4nKwSEz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to NumPy for the stratifier\n",
        "y = train_val_data.finding_labels.numpy()   # shape: [N, C]\n",
        "X = np.arange(len(train_val_data))          # dummy feature array\n",
        "\n",
        "#Stratified Splitting\n",
        "msss = MultilabelStratifiedShuffleSplit(\n",
        "    n_splits=1,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "#only want the first split & get train and validation indices\n",
        "train_idx, valid_idx = next(msss.split(X, y))\n",
        "\n",
        "# Get train and validation datasets based on the indices\n",
        "train_data = Subset(train_val_data, train_idx)\n",
        "valid_data = Subset(train_val_data, valid_idx)"
      ],
      "metadata": {
        "id": "Q_fal_8lwVXD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders for training and validation\n",
        "n = 32\n",
        "train_loader = DataLoader(train_data, batch_size=n, shuffle=True, num_workers=2, pin_memory=True)\n",
        "train_N = len(train_loader.dataset)\n",
        "valid_loader = DataLoader(valid_data, batch_size=n, num_workers=2, pin_memory=True)\n",
        "valid_N = len(valid_loader.dataset)"
      ],
      "metadata": {
        "id": "C8BhcKvUwV8-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding class weights\n",
        "def compute_pos_weights(subset):\n",
        "\n",
        "    # Get all labels that are in the subset\n",
        "    full_dataset = subset.dataset\n",
        "    labels = full_dataset.finding_labels[subset.indices].numpy()\n",
        "\n",
        "    pos_counts = labels.sum(axis = 0) #counts how many of each disease present in the dataset\n",
        "    neg_counts = (labels == 0).sum(axis = 0) # counts how many times each disease was NOT present in the dataset\n",
        "    pos_weight = neg_counts / (pos_counts + 1e-6) # Ratio of negatives to positives. 1e-6 to prevent dividing by 0.\n",
        "\n",
        "    return torch.tensor(pos_weight, dtype = torch.float32) #Convert to tensor\n",
        "\n",
        "# Using Focal Loss as loss function\n",
        "class Focal_Loss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, pos_weight=None):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self .pos_weight = pos_weight\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # logits: (B, C)\n",
        "        # targets: (B, C)\n",
        "\n",
        "        # 1. Compute BCE with logits, elementwise (NO reduction)\n",
        "        bce = F.binary_cross_entropy_with_logits(\n",
        "            logits,\n",
        "            targets,\n",
        "            pos_weight=self.pos_weight,\n",
        "            reduction='none'\n",
        "        )\n",
        "\n",
        "        # 2. Compute p_t = sigmoid(logits) for focal term\n",
        "        probs = torch.sigmoid(logits)\n",
        "        p_t = probs * targets + (1 - probs) * (1 - targets)\n",
        "\n",
        "        # 3. Apply focal modulation\n",
        "        focal_factor = (1 - p_t) ** self.gamma\n",
        "\n",
        "        # 4. Combine\n",
        "        loss = focal_factor * bce\n",
        "\n",
        "        # 5. Reduce mean\n",
        "        return loss.mean()"
      ],
      "metadata": {
        "id": "Ps_4wuXXwXzL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the same 224 x 224 image size for EfficientNet-B4\n",
        "\n",
        "class EfficientNetB4_Classifier(nn.Module):\n",
        "    def __init__(self, num_classes=15):\n",
        "        super().__init__()\n",
        "        self.backbone = EfficientNet.from_pretrained(\"efficientnet-b4\")\n",
        "        self.feature_dim = 1792\n",
        "        self.classifier = nn.Linear(self.feature_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.shape[1] == 1:\n",
        "            x = x.repeat(1, 3, 1, 1)\n",
        "        feats = self.backbone.extract_features(x)\n",
        "        feats = F.adaptive_avg_pool2d(feats, 1).view(x.size(0), -1)\n",
        "        return self.classifier(feats)\n",
        "\n",
        "effnet_model = EfficientNetB4_Classifier(num_classes=15).to(device)\n",
        "\n",
        "# Freeze backbone; Classifier unfrozen\n",
        "for param in effnet_model.backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "print(\"EfficientNet frozen\")\n",
        "\n",
        "\n",
        "pos_weight = compute_pos_weights(train_data).to(device) # Addressing class imbalance: add more weight to rare diseases\n",
        "pos_weight = torch.clamp(pos_weight, max=30) # Because one of the values was > 600\n",
        "loss_function = Focal_Loss(gamma=2.0, pos_weight=pos_weight)\n",
        "optimizer = Adam(effnet_model.classifier.parameters(), lr=1e-3) #increase classifiers learning rate\n",
        "effnet_model = effnet_model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3aEOdFdxCl5",
        "outputId": "69c62a19-f84f-4894-8b1d-f3b5368d8fe1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74.4M/74.4M [00:00<00:00, 112MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b4\n",
            "EfficientNet frozen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve\n",
        "import torch\n",
        "\n",
        "def pr_curve_thresholds(y_true, y_prob, min_thresh=0.1):\n",
        "    num_labels = y_true.shape[1]\n",
        "    thresholds = np.zeros(num_labels)\n",
        "\n",
        "    for i in range(num_labels):\n",
        "        p, r, t = precision_recall_curve(y_true[:, i], y_prob[:, i])\n",
        "        f1 = 2 * p * r / (p + r + 1e-9)\n",
        "\n",
        "        if len(t) == 0:\n",
        "            thresholds[i] = min_thresh  # Ensure thresholds are not all zero\n",
        "        else:\n",
        "            thresholds[i] = t[np.argmax(f1)]\n",
        "\n",
        "    return thresholds\n",
        "\n",
        "def compute_f1(y_true, y_prob, thresholds):\n",
        "\n",
        "    y_true = y_true.cpu()\n",
        "    y_prob = y_prob.cpu()\n",
        "\n",
        "    # Converts thresholds into tensors and match the shape of y_prob\n",
        "    thresholds = torch.tensor(thresholds, dtype = y_prob.dtype)\n",
        "    y_pred = (y_prob >= thresholds.unsqueeze(0)).int()\n",
        "\n",
        "    return f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "def compute_auc(y_true, y_prob):\n",
        "\n",
        "    y_true = y_true.detach().cpu().numpy() #binary labels\n",
        "    y_prob = y_prob.detach().cpu().numpy() #sigmoid probabilities\n",
        "\n",
        "    return roc_auc_score(y_true, y_prob, average = \"macro\")"
      ],
      "metadata": {
        "id": "XtKJhXWMwdPH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_loader, optimizer, loss_fn, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    for imgs, labels, _ in train_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        batch_loss = loss_fn(outputs, labels)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += batch_loss.item()\n",
        "\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        all_probs.append(probs.detach().cpu())\n",
        "        all_labels.append(labels.detach().cpu())\n",
        "\n",
        "    all_probs = torch.cat(all_probs)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    auc = compute_auc(all_labels, all_probs)\n",
        "    epoch_loss = total_loss / len(train_loader)\n",
        "\n",
        "    print(f\"Train - Loss: {epoch_loss:.4f}, AUC: {auc:.4f}\")\n",
        "    return epoch_loss, auc\n",
        "\n",
        "def validate_epoch(model, valid_loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels, _ in valid_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            batch_loss = loss_fn(outputs, labels)\n",
        "\n",
        "            total_loss += batch_loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            all_probs.append(probs.detach().cpu())\n",
        "            all_labels.append(labels.detach().cpu())\n",
        "\n",
        "    all_probs = torch.cat(all_probs)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    epoch_loss = total_loss / len(valid_loader)\n",
        "    thresholds = pr_curve_thresholds(all_labels.numpy(), all_probs.numpy())\n",
        "    valid_f1 = compute_f1(all_labels, all_probs, thresholds)\n",
        "    valid_auc = compute_auc(all_labels, all_probs)\n",
        "\n",
        "    print(f\"Valid - Loss: {epoch_loss:.4f}, F1: {valid_f1:.4f}, AUC: {valid_auc:.4f}\")\n",
        "    return epoch_loss, valid_f1, valid_auc, thresholds"
      ],
      "metadata": {
        "id": "oseeTpQswj9T"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "best_val_auc = 0.0\n",
        "best_model_path_effnet = \"/content/drive/Shareddrives/STA_160/nih_efficientnetb4_finetuned_best_head.pth\"\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
        "\n",
        "    train_loss, train_auc = train_epoch(\n",
        "        model=effnet_model,\n",
        "        train_loader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        loss_fn=loss_function,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    valid_loss, valid_f1, valid_auc, thresholds = validate_epoch(\n",
        "        model=effnet_model,\n",
        "        valid_loader=valid_loader,\n",
        "        loss_fn=loss_function,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    if valid_auc > best_val_auc:\n",
        "        best_val_auc = valid_auc\n",
        "        torch.save(effnet_model.state_dict(), best_model_path_effnet)\n",
        "        print(f\"New best EfficientNet-B4 model saved with AUC {best_val_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "eTsvxEoUwoMF",
        "outputId": "0aabb865-f4b2-49f0-8e33-f9b1d05fac83"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1373619651.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nEpoch {epoch + 1}/{EPOCHS}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     train_loss, train_auc = train_epoch(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meffnet_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1422548675.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2209656479.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mdrop_connect_rate\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# scale drop connect_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# Head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_depthwise_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# Squeeze and Excitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/efficientnet_pytorch/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMemoryEfficientSwish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSwishImplementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/efficientnet_pytorch/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze last layer of EfficientNet\n",
        "for param in effnet_model.backbone._blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Update learning rates for optimizer\n",
        "optimizer = Adam([\n",
        "    {\"params\": effnet_model.classifier.parameters(), \"lr\": 1e-3},\n",
        "    {\"params\": effnet_model.backbone._blocks[-1].parameters(), \"lr\": 1e-4},\n",
        "])"
      ],
      "metadata": {
        "id": "spc0nZSByKeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS_FINE = 20\n",
        "best_val_auc_fine = 0.0\n",
        "best_model_path_effnet_fine = \"/content/drive/Shareddrives/STA_160/nih_efficientnetb4_finetuned_best_full.pth\"\n",
        "\n",
        "for epoch in range(EPOCHS_FINE):\n",
        "    print(f\"\\nFine tune Epoch {epoch + 1}/{EPOCHS_FINE}\")\n",
        "\n",
        "    train_loss, train_auc = train_epoch(\n",
        "        model=effnet_model,\n",
        "        train_loader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        loss_fn=loss_function,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    valid_loss, valid_f1, valid_auc, thresholds = validate_epoch(\n",
        "        model=effnet_model,\n",
        "        valid_loader=valid_loader,\n",
        "        loss_fn=loss_function,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    if valid_auc > best_val_auc_fine:\n",
        "        best_val_auc_fine = valid_auc\n",
        "        torch.save(effnet_model.state_dict(), best_model_path_effnet_fine)\n",
        "        print(f\"New best fine tuned EfficientNet-B4 saved with AUC {best_val_auc_fine:.4f}\")"
      ],
      "metadata": {
        "id": "SOc-slsXzA_i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}