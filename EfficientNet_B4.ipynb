{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMAg0AjTReKSQGjezrel9B7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luck1e23/STA160-Team-11-Project/blob/Tina/EfficientNet_B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cj7iDbtGuy0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87debc97-45ba-49d9-b266-179690e4e3e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchxrayvision\n",
        "!pip install iterative-stratification\n",
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrFdddGgwGnr",
        "outputId": "1af638e9-6089-4a0a-ba37-405b0d7fc1f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchxrayvision\n",
            "  Downloading torchxrayvision-1.4.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: torch>=1 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (0.24.0+cu126)\n",
            "Requirement already satisfied: scikit-image>=0.16 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (0.25.2)\n",
            "Requirement already satisfied: tqdm>=4 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.2.2)\n",
            "Requirement already satisfied: requests>=1 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.32.4)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (11.3.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (from torchxrayvision) (2.37.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1->torchxrayvision) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1->torchxrayvision) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1->torchxrayvision) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=1->torchxrayvision) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=1->torchxrayvision) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=1->torchxrayvision) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=1->torchxrayvision) (2025.11.12)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (1.16.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (3.6)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.16->torchxrayvision) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1->torchxrayvision) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1->torchxrayvision) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1->torchxrayvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1->torchxrayvision) (3.0.3)\n",
            "Downloading torchxrayvision-1.4.0-py3-none-any.whl (29.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchxrayvision\n",
            "Successfully installed torchxrayvision-1.4.0\n",
            "Collecting iterative-stratification\n",
            "  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from iterative-stratification) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from iterative-stratification) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from iterative-stratification) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->iterative-stratification) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->iterative-stratification) (3.6.0)\n",
            "Downloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\n",
            "Installing collected packages: iterative-stratification\n",
            "Successfully installed iterative-stratification-0.1.9\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from efficientnet_pytorch) (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->efficientnet_pytorch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->efficientnet_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->efficientnet_pytorch) (3.0.3)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=a256ab5e513d29fd3e0a0c498c013998cbbc1588a7c4a59c97f605abedcdc568\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/3f/43/e6271c7026fe08c185da2be23c98c8e87477d3db63f41f32ad\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim import Adam\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
        "from pathlib import Path\n",
        "\n",
        "# Visualization tools\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Pre-trained Model: torchxrayvision\n",
        "import torchxrayvision as xrv\n",
        "import skimage\n",
        "\n",
        "# Pre-trained Modedl: EfficientNet\n",
        "from efficientnet_pytorch import EfficientNet\n"
      ],
      "metadata": {
        "id": "iZDo4vtWwISa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "file_path = '/content/drive/Shareddrives/STA_160/dataset/Data_Entry_2017.csv'\n",
        "train_val = '/content/drive/Shareddrives/STA_160/dataset/train_val_list.txt'\n",
        "test = '/content/drive/Shareddrives/STA_160/dataset/test_list.txt'\n",
        "resized_root = '/content/dataset_resized'   # Where resized images will be saved"
      ],
      "metadata": {
        "id": "5fbg1Xr7wKgY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "7vhGbPTzyunq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzipping the resized dataset from shared drives\n",
        "!unzip -q /content/drive/Shareddrives/STA_160/NIH_resized.zip -d /content/dataset\n",
        "\n",
        "!mkdir -p /content/dataset_resized\n",
        "# Finds all image files inside subfolders\n",
        "!find /content/dataset/content/dataset_resized/ -type f -exec mv -t /content/dataset_resized/ {} +\n",
        "!rm -rf /content/dataset/content #remove folder"
      ],
      "metadata": {
        "id": "fTBde1BgwO9a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Class\n",
        "class NIHXrays(Dataset):\n",
        "    def __init__(self, file_path, dataset_root, list_file=None, transform=None):\n",
        "        self.data = pd.read_csv(file_path)\n",
        "        self.dataset_root = dataset_root\n",
        "        self.transform = transform\n",
        "\n",
        "        # Optional filtering\n",
        "        if list_file:\n",
        "            with open(list_file, 'r') as f:\n",
        "                image_list = {line.strip() for line in f.readlines()}\n",
        "            self.data = self.data[self.data['Image Index'].isin(image_list)].reset_index(drop=True)\n",
        "\n",
        "        # Create label map\n",
        "        all_labels = set()\n",
        "        for labels in self.data['Finding Labels']:\n",
        "            for l in labels.split('|'):\n",
        "                all_labels.add(l.strip())\n",
        "\n",
        "        self.all_labels = sorted(all_labels)\n",
        "        self.label_map = {label: i for i, label in enumerate(self.all_labels)}\n",
        "\n",
        "        # Build multi-hot label vectors\n",
        "        self.finding_labels = []\n",
        "        for labels in self.data['Finding Labels']:\n",
        "            vec = torch.zeros(len(self.all_labels))\n",
        "            for l in labels.split('|'):\n",
        "                if l.strip() in self.label_map:\n",
        "                    vec[self.label_map[l.strip()]] = 1.0\n",
        "            self.finding_labels.append(vec)\n",
        "\n",
        "        self.finding_labels = torch.stack(self.finding_labels).float()\n",
        "\n",
        "        # Recursively map image filenames to full paths\n",
        "        self.image_map = {}\n",
        "        for img_path in Path(dataset_root).rglob(\"*.png\"):\n",
        "            self.image_map[img_path.name] = str(img_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.data.iloc[idx]['Image Index']\n",
        "\n",
        "        if img_name not in self.image_map:\n",
        "            raise FileNotFoundError(f\"Image {img_name} not found.\")\n",
        "\n",
        "        # Load Image\n",
        "        img = Image.open(self.image_map[img_name]).convert(\"L\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "          img = self.transform(img)\n",
        "\n",
        "        img = np.array(img).astype(np.float32) # PIL image --> NumPy\n",
        "\n",
        "        # XRV normalizaiton\n",
        "        img = xrv.datasets.normalize(img, maxval=255)\n",
        "\n",
        "        #   NumPy --> Tensor\n",
        "        img = torch.from_numpy(img).unsqueeze(0)\n",
        "\n",
        "        label = self.finding_labels[idx].float()\n",
        "\n",
        "        return img, label, img_name"
      ],
      "metadata": {
        "id": "P_b9OXF-wQvk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "rand_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip()\n",
        "])\n",
        "\n",
        "train_val_data = NIHXrays(file_path, resized_root, list_file=train_val, transform=rand_transforms)\n",
        "test_data      = NIHXrays(file_path, resized_root, list_file=test, transform=None)"
      ],
      "metadata": {
        "id": "IBpAZ4nKwSEz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to NumPy for the stratifier\n",
        "y = train_val_data.finding_labels.numpy()   # shape: [N, C]\n",
        "X = np.arange(len(train_val_data))          # dummy feature array\n",
        "\n",
        "#Stratified Splitting\n",
        "msss = MultilabelStratifiedShuffleSplit(\n",
        "    n_splits=1,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "#only want the first split & get train and validation indices\n",
        "train_idx, valid_idx = next(msss.split(X, y))\n",
        "\n",
        "# Get train and validation datasets based on the indices\n",
        "train_data = Subset(train_val_data, train_idx)\n",
        "valid_data = Subset(train_val_data, valid_idx)"
      ],
      "metadata": {
        "id": "Q_fal_8lwVXD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders for training and validation\n",
        "n = 32\n",
        "train_loader = DataLoader(train_data, batch_size=n, shuffle=True, num_workers=2, pin_memory=True)\n",
        "train_N = len(train_loader.dataset)\n",
        "valid_loader = DataLoader(valid_data, batch_size=n, num_workers=2, pin_memory=True)\n",
        "valid_N = len(valid_loader.dataset)"
      ],
      "metadata": {
        "id": "C8BhcKvUwV8-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding class weights\n",
        "def compute_pos_weights(subset):\n",
        "\n",
        "    # Get all labels that are in the subset\n",
        "    full_dataset = subset.dataset\n",
        "    labels = full_dataset.finding_labels[subset.indices].numpy()\n",
        "\n",
        "    pos_counts = labels.sum(axis = 0) #counts how many of each disease present in the dataset\n",
        "    neg_counts = (labels == 0).sum(axis = 0) # counts how many times each disease was NOT present in the dataset\n",
        "    pos_weight = neg_counts / (pos_counts + 1e-6) # Ratio of negatives to positives. 1e-6 to prevent dividing by 0.\n",
        "\n",
        "    return torch.tensor(pos_weight, dtype = torch.float32) #Convert to tensor\n",
        "\n",
        "# Using Focal Loss as loss function\n",
        "class Focal_Loss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, pos_weight=None):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self .pos_weight = pos_weight\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        # logits: (B, C)\n",
        "        # targets: (B, C)\n",
        "\n",
        "        # 1. Compute BCE with logits, elementwise (NO reduction)\n",
        "        bce = F.binary_cross_entropy_with_logits(\n",
        "            logits,\n",
        "            targets,\n",
        "            pos_weight=self.pos_weight,\n",
        "            reduction='none'\n",
        "        )\n",
        "\n",
        "        # 2. Compute p_t = sigmoid(logits) for focal term\n",
        "        probs = torch.sigmoid(logits)\n",
        "        p_t = probs * targets + (1 - probs) * (1 - targets)\n",
        "\n",
        "        # 3. Apply focal modulation\n",
        "        focal_factor = (1 - p_t) ** self.gamma\n",
        "\n",
        "        # 4. Combine\n",
        "        loss = focal_factor * bce\n",
        "\n",
        "        # 5. Reduce mean\n",
        "        return loss.mean()"
      ],
      "metadata": {
        "id": "Ps_4wuXXwXzL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the same 224 x 224 image size for EfficientNet-B4\n",
        "\n",
        "class EfficientNetB4_Classifier(nn.Module):\n",
        "    def __init__(self, num_classes=15):\n",
        "        super().__init__()\n",
        "        self.backbone = EfficientNet.from_pretrained(\"efficientnet-b4\")\n",
        "        self.feature_dim = 1792\n",
        "        self.classifier = nn.Linear(self.feature_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.shape[1] == 1:\n",
        "            x = x.repeat(1, 3, 1, 1)\n",
        "        feats = self.backbone.extract_features(x)\n",
        "        feats = F.adaptive_avg_pool2d(feats, 1).view(x.size(0), -1)\n",
        "        return self.classifier(feats)\n",
        "\n",
        "effnet_model = EfficientNetB4_Classifier(num_classes=15).to(device)\n",
        "\n",
        "# Freeze backbone; Classifier unfrozen\n",
        "for param in effnet_model.backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "print(\"EfficientNet frozen\")\n",
        "\n",
        "\n",
        "pos_weight = compute_pos_weights(train_data).to(device) # Addressing class imbalance: add more weight to rare diseases\n",
        "pos_weight = torch.clamp(pos_weight, max=30) # Because one of the values was > 600\n",
        "loss_function = Focal_Loss(gamma=2.0, pos_weight=pos_weight)\n",
        "optimizer = Adam(effnet_model.classifier.parameters(), lr=1e-3) #increase classifiers learning rate\n",
        "effnet_model = effnet_model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3aEOdFdxCl5",
        "outputId": "0a93c1cb-3268-42ef-8f68-06bc745e2b27"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b4-6ed6700e.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b4-6ed6700e.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 74.4M/74.4M [00:01<00:00, 50.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b4\n",
            "EfficientNet frozen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve\n",
        "import torch\n",
        "\n",
        "def pr_curve_thresholds(y_true, y_prob, min_thresh=0.1):\n",
        "    num_labels = y_true.shape[1]\n",
        "    thresholds = np.zeros(num_labels)\n",
        "\n",
        "    for i in range(num_labels):\n",
        "        p, r, t = precision_recall_curve(y_true[:, i], y_prob[:, i])\n",
        "        f1 = 2 * p * r / (p + r + 1e-9)\n",
        "\n",
        "        if len(t) == 0:\n",
        "            thresholds[i] = min_thresh  # Ensure thresholds are not all zero\n",
        "        else:\n",
        "            thresholds[i] = t[np.argmax(f1)]\n",
        "\n",
        "    return thresholds\n",
        "\n",
        "def compute_f1(y_true, y_prob, thresholds):\n",
        "\n",
        "    y_true = y_true.cpu()\n",
        "    y_prob = y_prob.cpu()\n",
        "\n",
        "    # Converts thresholds into tensors and match the shape of y_prob\n",
        "    thresholds = torch.tensor(thresholds, dtype = y_prob.dtype)\n",
        "    y_pred = (y_prob >= thresholds.unsqueeze(0)).int()\n",
        "\n",
        "    return f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "def compute_auc(y_true, y_prob):\n",
        "\n",
        "    y_true = y_true.detach().cpu().numpy() #binary labels\n",
        "    y_prob = y_prob.detach().cpu().numpy() #sigmoid probabilities\n",
        "\n",
        "    return roc_auc_score(y_true, y_prob, average = \"macro\")"
      ],
      "metadata": {
        "id": "XtKJhXWMwdPH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_loader, optimizer, loss_fn, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    for imgs, labels, _ in train_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        batch_loss = loss_fn(outputs, labels)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += batch_loss.item()\n",
        "\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        all_probs.append(probs.detach().cpu())\n",
        "        all_labels.append(labels.detach().cpu())\n",
        "\n",
        "    all_probs = torch.cat(all_probs)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    auc = compute_auc(all_labels, all_probs)\n",
        "    epoch_loss = total_loss / len(train_loader)\n",
        "\n",
        "    print(f\"Train - Loss: {epoch_loss:.4f}, AUC: {auc:.4f}\")\n",
        "    return epoch_loss, auc\n",
        "\n",
        "def validate_epoch(model, valid_loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels, _ in valid_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            batch_loss = loss_fn(outputs, labels)\n",
        "\n",
        "            total_loss += batch_loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(outputs)\n",
        "            all_probs.append(probs.detach().cpu())\n",
        "            all_labels.append(labels.detach().cpu())\n",
        "\n",
        "    all_probs = torch.cat(all_probs)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    epoch_loss = total_loss / len(valid_loader)\n",
        "    thresholds = pr_curve_thresholds(all_labels.numpy(), all_probs.numpy())\n",
        "    valid_f1 = compute_f1(all_labels, all_probs, thresholds)\n",
        "    valid_auc = compute_auc(all_labels, all_probs)\n",
        "\n",
        "    print(f\"Valid - Loss: {epoch_loss:.4f}, F1: {valid_f1:.4f}, AUC: {valid_auc:.4f}\")\n",
        "    return epoch_loss, valid_f1, valid_auc, thresholds"
      ],
      "metadata": {
        "id": "oseeTpQswj9T"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "best_val_auc = 0.0\n",
        "best_model_path_effnet = \"/content/drive/Shareddrives/STA_160/nih_efficientnetb4_finetuned_best_head.pth\"\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
        "\n",
        "    train_loss, train_auc = train_epoch(\n",
        "        model=effnet_model,\n",
        "        train_loader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        loss_fn=loss_function,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    valid_loss, valid_f1, valid_auc, thresholds = validate_epoch(\n",
        "        model=effnet_model,\n",
        "        valid_loader=valid_loader,\n",
        "        loss_fn=loss_function,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    if valid_auc > best_val_auc:\n",
        "        best_val_auc = valid_auc\n",
        "        torch.save(effnet_model.state_dict(), best_model_path_effnet)\n",
        "        print(f\"New best EfficientNet-B4 model saved with AUC {best_val_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTsvxEoUwoMF",
        "outputId": "acfcdff4-60d7-40ff-83ce-d717b0c2b98f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "Train - Loss: 0.2518, AUC: 0.6564\n",
            "Valid - Loss: 0.2463, F1: 0.1915, AUC: 0.6857\n",
            "New best EfficientNet-B4 model saved with AUC 0.6857\n",
            "\n",
            "Epoch 2/5\n",
            "Train - Loss: 0.2476, AUC: 0.6824\n",
            "Valid - Loss: 0.2454, F1: 0.1933, AUC: 0.6903\n",
            "New best EfficientNet-B4 model saved with AUC 0.6903\n",
            "\n",
            "Epoch 3/5\n",
            "Train - Loss: 0.2468, AUC: 0.6887\n",
            "Valid - Loss: 0.2464, F1: 0.1930, AUC: 0.6939\n",
            "New best EfficientNet-B4 model saved with AUC 0.6939\n",
            "\n",
            "Epoch 4/5\n",
            "Train - Loss: 0.2457, AUC: 0.6952\n",
            "Valid - Loss: 0.2447, F1: 0.2011, AUC: 0.7002\n",
            "New best EfficientNet-B4 model saved with AUC 0.7002\n",
            "\n",
            "Epoch 5/5\n",
            "Train - Loss: 0.2456, AUC: 0.6958\n",
            "Valid - Loss: 0.2465, F1: 0.1951, AUC: 0.6960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze last layer of EfficientNet\n",
        "for param in effnet_model.backbone._blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Update learning rates for optimizer\n",
        "optimizer = Adam([\n",
        "    {\"params\": effnet_model.classifier.parameters(), \"lr\": 1e-3},\n",
        "    {\"params\": effnet_model.backbone._blocks[-1].parameters(), \"lr\": 1e-4},\n",
        "])"
      ],
      "metadata": {
        "id": "spc0nZSByKeH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS_FINE = 20\n",
        "best_val_auc_fine = 0.0\n",
        "best_model_path_effnet_fine = \"/content/drive/Shareddrives/STA_160/nih_efficientnetb4_finetuned_best_full.pth\"\n",
        "\n",
        "for epoch in range(EPOCHS_FINE):\n",
        "    print(f\"\\nFine tune Epoch {epoch + 1}/{EPOCHS_FINE}\")\n",
        "\n",
        "    train_loss, train_auc = train_epoch(\n",
        "        model=effnet_model,\n",
        "        train_loader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        loss_fn=loss_function,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    valid_loss, valid_f1, valid_auc, thresholds = validate_epoch(\n",
        "        model=effnet_model,\n",
        "        valid_loader=valid_loader,\n",
        "        loss_fn=loss_function,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    if valid_auc > best_val_auc_fine:\n",
        "        best_val_auc_fine = valid_auc\n",
        "        torch.save(effnet_model.state_dict(), best_model_path_effnet_fine)\n",
        "        print(f\"New best fine tuned EfficientNet-B4 saved with AUC {best_val_auc_fine:.4f}\")"
      ],
      "metadata": {
        "id": "SOc-slsXzA_i",
        "outputId": "7b0cfd18-78c5-469f-be48-94b8d1e86164",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fine tune Epoch 1/20\n",
            "Train - Loss: 0.2378, AUC: 0.7140\n",
            "Valid - Loss: 0.2346, F1: 0.2138, AUC: 0.7247\n",
            "New best fine tuned EfficientNet-B4 saved with AUC 0.7247\n",
            "\n",
            "Fine tune Epoch 2/20\n",
            "Train - Loss: 0.2314, AUC: 0.7313\n",
            "Valid - Loss: 0.2346, F1: 0.2122, AUC: 0.7263\n",
            "New best fine tuned EfficientNet-B4 saved with AUC 0.7263\n",
            "\n",
            "Fine tune Epoch 3/20\n",
            "Train - Loss: 0.2286, AUC: 0.7400\n",
            "Valid - Loss: 0.2333, F1: 0.2166, AUC: 0.7296\n",
            "New best fine tuned EfficientNet-B4 saved with AUC 0.7296\n",
            "\n",
            "Fine tune Epoch 4/20\n",
            "Train - Loss: 0.2271, AUC: 0.7471\n",
            "Valid - Loss: 0.2304, F1: 0.2201, AUC: 0.7395\n",
            "New best fine tuned EfficientNet-B4 saved with AUC 0.7395\n",
            "\n",
            "Fine tune Epoch 5/20\n",
            "Train - Loss: 0.2258, AUC: 0.7510\n",
            "Valid - Loss: 0.2307, F1: 0.2233, AUC: 0.7400\n",
            "New best fine tuned EfficientNet-B4 saved with AUC 0.7400\n",
            "\n",
            "Fine tune Epoch 6/20\n",
            "Train - Loss: 0.2240, AUC: 0.7572\n",
            "Valid - Loss: 0.2311, F1: 0.2226, AUC: 0.7418\n",
            "New best fine tuned EfficientNet-B4 saved with AUC 0.7418\n",
            "\n",
            "Fine tune Epoch 7/20\n",
            "Train - Loss: 0.2214, AUC: 0.7644\n",
            "Valid - Loss: 0.2336, F1: 0.2244, AUC: 0.7392\n",
            "\n",
            "Fine tune Epoch 8/20\n",
            "Train - Loss: 0.2205, AUC: 0.7669\n",
            "Valid - Loss: 0.2323, F1: 0.2271, AUC: 0.7421\n",
            "New best fine tuned EfficientNet-B4 saved with AUC 0.7421\n",
            "\n",
            "Fine tune Epoch 9/20\n",
            "Train - Loss: 0.2192, AUC: 0.7697\n",
            "Valid - Loss: 0.2313, F1: 0.2287, AUC: 0.7440\n",
            "New best fine tuned EfficientNet-B4 saved with AUC 0.7440\n",
            "\n",
            "Fine tune Epoch 10/20\n",
            "Train - Loss: 0.2181, AUC: 0.7738\n",
            "Valid - Loss: 0.2319, F1: 0.2276, AUC: 0.7446\n",
            "New best fine tuned EfficientNet-B4 saved with AUC 0.7446\n",
            "\n",
            "Fine tune Epoch 11/20\n",
            "Train - Loss: 0.2155, AUC: 0.7811\n",
            "Valid - Loss: 0.2329, F1: 0.2317, AUC: 0.7459\n",
            "New best fine tuned EfficientNet-B4 saved with AUC 0.7459\n",
            "\n",
            "Fine tune Epoch 12/20\n",
            "Train - Loss: 0.2148, AUC: 0.7820\n",
            "Valid - Loss: 0.2337, F1: 0.2294, AUC: 0.7404\n",
            "\n",
            "Fine tune Epoch 13/20\n",
            "Train - Loss: 0.2129, AUC: 0.7868\n"
          ]
        }
      ]
    }
  ]
}