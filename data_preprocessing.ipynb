{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luck1e23/STA160-Team-11-Project/blob/main/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XygmfDJQrVKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f84e3a16-43c7-4667-e906-2cbf6fcd63a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchxrayvision\n",
        "!pip install iterative-stratification\n",
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "id": "fO57a1XV-g1B",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Packages"
      ],
      "metadata": {
        "id": "UMaZLheYLESe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.optim import Adam\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve\n",
        "\n",
        "# Visualization tools\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Pre-trained Model: torchxrayvision\n",
        "import torchxrayvision as xrv\n",
        "import skimage\n",
        "\n",
        "# Pre-trained Modedl: EfficientNet\n",
        "from efficientnet_pytorch import EfficientNet\n"
      ],
      "metadata": {
        "id": "5Tz4bz8OYrF0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-Trained Model"
      ],
      "metadata": {
        "id": "gqqJPSC5LG-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XRV Pathology Classifiers :: NIH chest X-ray8\n",
        "xrv_model = xrv.models.DenseNet(weights=\"densenet121-res224-nih\")"
      ],
      "metadata": {
        "id": "20kXR5Qo-mRm",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File Paths"
      ],
      "metadata": {
        "id": "T4zf1j7TLNcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "file_path = '/content/drive/Shareddrives/STA_160/dataset/Data_Entry_2017.csv'\n",
        "train_val = '/content/drive/Shareddrives/STA_160/dataset/train_val_list.txt'\n",
        "test = '/content/drive/Shareddrives/STA_160/dataset/test_list.txt'\n",
        "resized_root = '/content/dataset_resized'   # Where resized images will be saved"
      ],
      "metadata": {
        "id": "FB3KHeztx0U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a 224 x 224 Resized Dataset"
      ],
      "metadata": {
        "id": "Sd3bmnIbLaeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Old Code for resizing the images before making a dataset class\n",
        "# Purpose was to speed up the running of the code\n",
        "\n",
        "# Target Size\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "for root, dirs, files in os.walk(dataset_root):\n",
        "    rel_path = os.path.relpath(root, dataset_root)\n",
        "    save_dir = os.path.join(resized_root, rel_path)\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for f in files:\n",
        "        if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            img_path = os.path.join(root, f)\n",
        "\n",
        "            # Load and convert to grayscale (preserve pixel values)\n",
        "            img = Image.open(img_path).convert(\"L\")\n",
        "            arr = np.array(img).astype(np.uint8)\n",
        "\n",
        "            # Resize using bilinear interpolation\n",
        "            img_resized = Image.fromarray(arr).resize(IMG_SIZE, Image.BILINEAR)\n",
        "\n",
        "            # Build output filename (always PNG)\n",
        "            base = os.path.splitext(f)[0]\n",
        "            out_path = os.path.join(save_dir, base + \".png\")\n",
        "\n",
        "            # Save as PNG to avoid JPEG compression artifacts\n",
        "            img_resized.save(out_path, format=\"PNG\")\n",
        "\n",
        "# Zip the resized dataset\n",
        "!zip -r -q /content/NIH_resized.zip /content/dataset_resized\n",
        "\n",
        "# Copy and upload to the shared drive\n",
        "!cp /content/NIH_resized.zip /content/drive/Shareddrives/STA_160/\n",
        "\n"
      ],
      "metadata": {
        "id": "GcFnymr_lVx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzipping the resized dataset from shared drives\n",
        "!unzip -q /content/drive/Shareddrives/STA_160/NIH_resized.zip -d /content/dataset\n",
        "\n",
        "!mkdir -p /content/dataset_resized\n",
        "# Finds all image files inside subfolders\n",
        "!find /content/dataset/content/dataset_resized/ -type f -exec mv -t /content/dataset_resized/ {} +\n",
        "!rm -rf /content/dataset/content #remove folder"
      ],
      "metadata": {
        "id": "3Z55TWVgMlei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "hAly1Xa8LWFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Class\n",
        "class NIHXrays(Dataset):\n",
        "    def __init__(self, file_path, dataset_root, list_file=None, transform=None):\n",
        "        self.data = pd.read_csv(file_path)\n",
        "        self.dataset_root = dataset_root\n",
        "        self.transform = transform\n",
        "\n",
        "        # Optional filtering\n",
        "        if list_file:\n",
        "            with open(list_file, 'r') as f:\n",
        "                image_list = {line.strip() for line in f.readlines()}\n",
        "            self.data = self.data[self.data['Image Index'].isin(image_list)].reset_index(drop=True)\n",
        "\n",
        "        # Create label map\n",
        "        all_labels = set()\n",
        "        for labels in self.data['Finding Labels']:\n",
        "            for l in labels.split('|'):\n",
        "                all_labels.add(l.strip())\n",
        "\n",
        "        self.all_labels = sorted(all_labels)\n",
        "        self.label_map = {label: i for i, label in enumerate(self.all_labels)}\n",
        "\n",
        "        # Build multi-hot label vectors\n",
        "        self.finding_labels = []\n",
        "        for labels in self.data['Finding Labels']:\n",
        "            vec = torch.zeros(len(self.all_labels))\n",
        "            for l in labels.split('|'):\n",
        "                if l.strip() in self.label_map:\n",
        "                    vec[self.label_map[l.strip()]] = 1.0\n",
        "            self.finding_labels.append(vec)\n",
        "\n",
        "        self.finding_labels = torch.stack(self.finding_labels).float()\n",
        "\n",
        "        # Recursively map image filenames to full paths\n",
        "        self.image_map = {}\n",
        "        for img_path in Path(dataset_root).rglob(\"*.png\"):\n",
        "            self.image_map[img_path.name] = str(img_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.data.iloc[idx]['Image Index']\n",
        "\n",
        "        if img_name not in self.image_map:\n",
        "            raise FileNotFoundError(f\"Image {img_name} not found.\")\n",
        "\n",
        "        # Load Image\n",
        "        img = Image.open(self.image_map[img_name]).convert(\"L\")\n",
        "\n",
        "        if self.transform is not None:\n",
        "          img = self.transform(img)\n",
        "\n",
        "        img = np.array(img).astype(np.float32) # PIL image --> NumPy\n",
        "\n",
        "        # XRV normalizaiton\n",
        "        img = xrv.datasets.normalize(img, maxval=255)\n",
        "\n",
        "        #   NumPy --> Tensor\n",
        "        img = torch.from_numpy(img).unsqueeze(0)\n",
        "\n",
        "        label = self.finding_labels[idx].float()\n",
        "\n",
        "        return img, label, img_name"
      ],
      "metadata": {
        "id": "6YWDipkc_-RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "rand_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip()\n",
        "])\n",
        "\n",
        "train_val_data = NIHXrays(file_path, resized_root, list_file=train_val, transform=rand_transforms)\n",
        "test_data      = NIHXrays(file_path, resized_root, list_file=test, transform=None)"
      ],
      "metadata": {
        "id": "Uj_QxJY4iETn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Label Stratified Split for Training and Validation"
      ],
      "metadata": {
        "id": "wvP1Ou_ELoge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to NumPy for the stratifier\n",
        "y = train_val_data.finding_labels.numpy()   # shape: [N, C]\n",
        "X = np.arange(len(train_val_data))          # dummy feature array\n",
        "\n",
        "#Stratified Splitting\n",
        "msss = MultilabelStratifiedShuffleSplit(\n",
        "    n_splits=1,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "#only want the first split & get train and validation indices\n",
        "train_idx, valid_idx = next(msss.split(X, y))\n",
        "\n",
        "# Get train and validation datasets based on the indices\n",
        "train_data = Subset(train_val_data, train_idx)\n",
        "valid_data = Subset(train_val_data, valid_idx)"
      ],
      "metadata": {
        "id": "oYKK4hGP79zX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation and Data Loader"
      ],
      "metadata": {
        "id": "sk5ynvR3KsJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders for training and validation\n",
        "n = 32\n",
        "train_loader = DataLoader(train_data, batch_size=n, shuffle=True, num_workers=2, pin_memory=True)\n",
        "train_N = len(train_loader.dataset)\n",
        "valid_loader = DataLoader(valid_data, batch_size=n, num_workers=2, pin_memory=True)\n",
        "valid_N = len(valid_loader.dataset)"
      ],
      "metadata": {
        "id": "zJNbI834Ki-I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}